{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distilling a Neural Network into Soft Decision Tree\n",
    "\n",
    "* Implementation based on [[Frosst & Hinton, 2017](http://arxiv.org/abs/1711.09784)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From d:\\IPython Notebooks\\afp\\applied_finance_project\\distill-nn-tree\\models\\utils.py:15: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n\n"
     ]
    }
   ],
   "source": [
    "from importlib import import_module\n",
    "\n",
    "distillnntree = import_module('distill-nn-tree.models')\n",
    "distillnntreeutils = import_module('distill-nn-tree.models.utils')\n",
    "\n",
    "ConvNet, SoftBinaryDecisionTree = distillnntree.ConvNet, distillnntree.SoftBinaryDecisionTree\n",
    "brand_new_tfsession, draw_tree = distillnntreeutils.brand_new_tfsession, distillnntreeutils.draw_tree\n",
    "\n",
    "\n",
    "sess = brand_new_tfsession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 28, 28, 1) (50000,) (10000, 28, 28, 1) (10000,) (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# add channel dim\n",
    "x_train, x_test = x_train[..., np.newaxis], x_test[..., np.newaxis]\n",
    "\n",
    "# hold out last 10000 training samples for validation\n",
    "x_valid, y_valid = x_train[-10000:], y_train[-10000:]\n",
    "x_train, y_train = x_train[:-10000], y_train[:-10000]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "28 28 1 10\n"
     ]
    }
   ],
   "source": [
    "# retrieve image and label shapes from training data\n",
    "img_rows, img_cols, img_chans = x_train.shape[1:]\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "\n",
    "print(img_rows, img_cols, img_chans, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 10) (10000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert labels to 1-hot vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, n_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs and cast to float\n",
    "x_train = (x_train / np.max(x_train)).astype(np.float32)\n",
    "x_valid = (x_valid / np.max(x_valid)).astype(np.float32)\n",
    "x_test = (x_test / np.max(x_test)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [ 
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading trained model from assets/nn-model.hdf5.\n",
      "WARNING:tensorflow:From D:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "accuracy: 99.90% | loss: 0.0032113500596674203\n"
     ]
    }
   ],
   "source": [
    "nn = ConvNet(img_rows, img_cols, img_chans, n_classes)\n",
    "nn.maybe_train(data_train=(x_train, y_train),\n",
    "               data_valid=(x_valid, y_valid),\n",
    "               batch_size=16, epochs=12)\n",
    "nn.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(None, 28, 28)]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "nn.model.layers[0].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 99.14% | loss: 0.03600480322143594\n",
      "accuracy: 99.20% | loss: 0.028137104455670123\n"
     ]
    }
   ],
   "source": [
    "nn.evaluate(x_valid, y_valid)\n",
    "nn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of soft labels for distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y_train_soft = nn.predict(x_train)\n",
    "y_train_soft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Soft Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten dataset in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (10000, 784))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "x_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
    "x_valid_flat = x_valid.reshape((x_valid.shape[0], -1))\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.imshow(x_test_flat.reshape((x_test_flat.shape[0], img_rows, img_cols))[1])\n",
    "\n",
    "x_train_flat.shape, x_valid_flat.shape, x_test_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "* `tree_depth`: as denoted in the [[paper](https://arxiv.org/pdf/1711.09784.pdf)], depth is in terms of inner nodes (excluding leaves / indexing depth from `0`)\n",
    "* `penalty_strength`: regularization penalty strength\n",
    "* `penalty_decay`: regularization penalty decay: paper authors found 0.5 optimal (note that $2^{-d} = 0.5^d$ as we use it)\n",
    "* `ema_win_size`: scaling factor to the \"default size of the window\" used to calculate moving averages (growing exponentially with depth) of node and path probabilities\n",
    "* `inv_temp`: scale logits of inner nodes to \"avoid very soft decisions\" [[paper](https://arxiv.org/pdf/1711.09784.pdf)]\n",
    "    * pass `0` to indicate that this should be a learned parameter (single scalar learned to apply to all nodes in the tree)\n",
    "* `learning_rate`: hopefully no need to explain, but let's be cool and use [Karpathy constant](https://www.urbandictionary.com/define.php?term=Karpathy%20Constant) ([source](https://twitter.com/karpathy/status/801621764144971776)) :D as default in `tree.__init__()`\n",
    "* `batch_size`: we use a small one, because with increasing depth and thus amount of leaf bigots, larger batch sizes cause their loss terms to be scaled down too much by averaging, which results in poor optimization properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = img_rows * img_cols * img_chans\n",
    "tree_depth = 4\n",
    "penalty_strength = 1e+1\n",
    "penalty_decay = 0.25\n",
    "ema_win_size = 1000\n",
    "inv_temp = 0.01\n",
    "learning_rate = 5e-03\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular training with hard labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Scale.call of <distill-nn-tree.models.tree.Scale object at 0x000002730E0D5F40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Scale.call of <distill-nn-tree.models.tree.Scale object at 0x000002730E0D5F40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LeftBranch.call of <distill-nn-tree.models.tree.LeftBranch object at 0x000002730E0D5400>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LeftBranch.call of <distill-nn-tree.models.tree.LeftBranch object at 0x000002730E0D5400>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method RightBranch.call of <distill-nn-tree.models.tree.RightBranch object at 0x000002730E6CA160>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RightBranch.call of <distill-nn-tree.models.tree.RightBranch object at 0x000002730E6CA160>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From d:\\IPython Notebooks\\afp\\applied_finance_project\\distill-nn-tree\\models\\tree.py:18: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method OutputLayer.call of <distill-nn-tree.models.tree.OutputLayer object at 0x000002730E571B50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method OutputLayer.call of <distill-nn-tree.models.tree.OutputLayer object at 0x000002730E571B50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From D:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:6094: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:AutoGraph could not transform <function OutputLayer.call.<locals>.from_keras_tensor.<locals>.<lambda> at 0x000002730E69E670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function OutputLayer.call.<locals>.from_keras_tensor.<locals>.<lambda> at 0x000002730E69E670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Built tree has 16 leaves out of 31 nodes\n"
     ]
    }
   ],
   "source": [
    "sess = brand_new_tfsession(sess)\n",
    "\n",
    "tree = SoftBinaryDecisionTree(tree_depth, n_features, n_classes,\n",
    "    penalty_strength=penalty_strength, penalty_decay=penalty_decay,\n",
    "    inv_temp=inv_temp, ema_win_size=ema_win_size, learning_rate=learning_rate)\n",
    "tree.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading trained model from assets/non-distilled/tree-model.\n",
      "assets/non-distilled/tree-model is not a valid checkpoint. Training from scratch.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "50000/50000 [==============================] - 92s 2ms/sample - loss: inf - acc: 0.5089 - val_loss: 7.8493 - val_acc: 0.7045\n",
      "Epoch 2/40\n",
      "50000/50000 [==============================] - 95s 2ms/sample - loss: 7.9288 - acc: 0.7420 - val_loss: 8.0198 - val_acc: 0.8212\n",
      "Epoch 3/40\n",
      "50000/50000 [==============================] - 96s 2ms/sample - loss: 8.0334 - acc: 0.8263 - val_loss: 8.0903 - val_acc: 0.8664\n",
      "Epoch 4/40\n",
      "50000/50000 [==============================] - 92s 2ms/sample - loss: 8.0646 - acc: 0.8565 - val_loss: 8.0805 - val_acc: 0.8789\n",
      "Epoch 5/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 8.0618 - acc: 0.8690 - val_loss: 8.0644 - val_acc: 0.8826\n",
      "Epoch 6/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0375 - acc: 0.8753 - val_loss: 8.0351 - val_acc: 0.8914\n",
      "Epoch 7/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0179 - acc: 0.8816 - val_loss: 8.0251 - val_acc: 0.8960\n",
      "Epoch 8/40\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 8.0119 - acc: 0.8865 - val_loss: 8.0328 - val_acc: 0.8979\n",
      "Epoch 9/40\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 8.0128 - acc: 0.8907 - val_loss: 8.0262 - val_acc: 0.9030\n",
      "Epoch 10/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9922 - acc: 0.8958 - val_loss: 8.0021 - val_acc: 0.9063\n",
      "Epoch 11/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9746 - acc: 0.8988 - val_loss: 8.0108 - val_acc: 0.9085\n",
      "Epoch 12/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9758 - acc: 0.9020 - val_loss: 7.9805 - val_acc: 0.9096\n",
      "Epoch 13/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9645 - acc: 0.9050 - val_loss: 7.9680 - val_acc: 0.9078\n",
      "Epoch 14/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9557 - acc: 0.9069 - val_loss: 7.9758 - val_acc: 0.9130\n",
      "Epoch 15/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9525 - acc: 0.9090 - val_loss: 7.9710 - val_acc: 0.9163\n",
      "Epoch 16/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9357 - acc: 0.9110 - val_loss: 7.9613 - val_acc: 0.9169\n",
      "Epoch 17/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9299 - acc: 0.9122 - val_loss: 7.9540 - val_acc: 0.9195\n",
      "Epoch 18/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9259 - acc: 0.9135 - val_loss: 7.9495 - val_acc: 0.9194\n",
      "Epoch 19/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9257 - acc: 0.9138 - val_loss: 7.9468 - val_acc: 0.9186\n",
      "Epoch 20/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9231 - acc: 0.9147 - val_loss: 7.9388 - val_acc: 0.9196\n",
      "Epoch 21/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9207 - acc: 0.9154 - val_loss: 7.9317 - val_acc: 0.9208\n",
      "Epoch 22/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9154 - acc: 0.9158 - val_loss: 7.9350 - val_acc: 0.9223\n",
      "Epoch 23/40\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 7.9181 - acc: 0.9179 - val_loss: 7.9247 - val_acc: 0.9225\n",
      "Epoch 24/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9163 - acc: 0.9176 - val_loss: 7.9338 - val_acc: 0.9232\n",
      "Epoch 25/40\n",
      "50000/50000 [==============================] - 104s 2ms/sample - loss: 7.9097 - acc: 0.9191 - val_loss: 7.9197 - val_acc: 0.9245\n",
      "Epoch 26/40\n",
      "50000/50000 [==============================] - 101s 2ms/sample - loss: 7.9015 - acc: 0.9195 - val_loss: 7.9281 - val_acc: 0.9236\n",
      "Epoch 27/40\n",
      "50000/50000 [==============================] - 98s 2ms/sample - loss: 7.9081 - acc: 0.9201 - val_loss: 7.9196 - val_acc: 0.9228\n",
      "Epoch 28/40\n",
      "50000/50000 [==============================] - 96s 2ms/sample - loss: 7.9072 - acc: 0.9213 - val_loss: 7.9270 - val_acc: 0.9226\n",
      "Epoch 29/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9084 - acc: 0.9222 - val_loss: 7.9228 - val_acc: 0.9255\n",
      "Epoch 30/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9042 - acc: 0.9222 - val_loss: 7.9264 - val_acc: 0.9252\n",
      "Epoch 31/40\n",
      "50000/50000 [==============================] - 93s 2ms/sample - loss: 7.8953 - acc: 0.9224 - val_loss: 7.9233 - val_acc: 0.9256\n",
      "Epoch 32/40\n",
      "50000/50000 [==============================] - 88s 2ms/sample - loss: 7.8912 - acc: 0.9230 - val_loss: 7.9042 - val_acc: 0.9252\n",
      "Epoch 33/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.8928 - acc: 0.9234 - val_loss: 7.9042 - val_acc: 0.9256\n",
      "Epoch 34/40\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 7.8895 - acc: 0.9241 - val_loss: 7.9193 - val_acc: 0.9260\n",
      "Epoch 35/40\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 7.8938 - acc: 0.9246 - val_loss: 7.9151 - val_acc: 0.9269\n",
      "Epoch 36/40\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.8945 - acc: 0.9251 - val_loss: 7.9145 - val_acc: 0.9267\n",
      "Epoch 37/40\n",
      "50000/50000 [==============================] - 89s 2ms/sample - loss: 7.9008 - acc: 0.9251 - val_loss: 7.9057 - val_acc: 0.9270\n",
      "Epoch 38/40\n",
      "50000/50000 [==============================] - 99s 2ms/sample - loss: 7.8928 - acc: 0.9251 - val_loss: 7.9080 - val_acc: 0.9271\n",
      "Epoch 39/40\n",
      "50000/50000 [==============================] - 98s 2ms/sample - loss: 7.8951 - acc: 0.9260 - val_loss: 7.9162 - val_acc: 0.9266\n",
      "Epoch 40/40\n",
      "50000/50000 [==============================] - 98s 2ms/sample - loss: 7.8924 - acc: 0.9270 - val_loss: 7.9062 - val_acc: 0.9278\n",
      "Saving trained model to assets/non-distilled/tree-model.\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience=20, verbose=1)\n",
    "\n",
    "'''If you wish to train your own model instead of loading one from checkpoint, remove the checkpoint.'''\n",
    "# os.remove('assets/non-distilled/checkpoint')\n",
    "# for f in glob.glob('assets/non-distilled/tree-model*'):\n",
    "#     os.remove(f)\n",
    "\n",
    "tree.maybe_train(\n",
    "    sess=sess, data_train=(x_train_flat, y_train), data_valid=(x_valid_flat, y_valid),\n",
    "    batch_size=batch_size, epochs=epochs, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 92.78% | loss: 7.908185776901245\n",
      "accuracy: 92.74% | loss: 7.897307242202759\n"
     ]
    }
   ],
   "source": [
    "tree.evaluate(x=x_valid_flat, y=y_valid, batch_size=batch_size)\n",
    "tree.evaluate(x=x_test_flat, y=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distillation: training with soft labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function OutputLayer.call.<locals>.from_keras_tensor.<locals>.<lambda> at 0x000002730EC9E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function OutputLayer.call.<locals>.from_keras_tensor.<locals>.<lambda> at 0x000002730EC9E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Built tree has 32 leaves out of 63 nodes\n"
     ]
    }
   ],
   "source": [
    "sess = brand_new_tfsession(sess)\n",
    "\n",
    "tree = SoftBinaryDecisionTree(tree_depth, n_features, n_classes,\n",
    "    penalty_strength=penalty_strength, penalty_decay=penalty_decay,\n",
    "    inv_temp=inv_temp, ema_win_size=ema_win_size, learning_rate=learning_rate)\n",
    "tree.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading trained model from assets/distilled/tree-model.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NotFoundError",
     "evalue": "FindFirstFile failed for: assets/distilled : The system cannot find the path specified.\r\n; No such process",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-81363e263497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     os.remove(f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m tree.maybe_train(\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_soft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     batch_size=batch_size, epochs=epochs, callbacks=[es], distill=True)\n",
      "\u001b[1;32md:\\IPython Notebooks\\afp\\applied_finance_project\\distill-nn-tree\\models\\tree.py\u001b[0m in \u001b[0;36mmaybe_train\u001b[1;34m(self, sess, data_train, data_valid, batch_size, epochs, callbacks, distill)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading trained model from {}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_MODEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPATH_MODEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\IPython Notebooks\\afp\\applied_finance_project\\distill-nn-tree\\models\\tree.py\u001b[0m in \u001b[0;36mload_variables\u001b[1;34m(self, sess, path)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[0mcheckpoint_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1289\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_exists_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1290\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n\u001b[0;32m   1291\u001b[0m                        checkpoint_prefix)\n",
      "\u001b[1;32mD:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_management.py\u001b[0m in \u001b[0;36mcheckpoint_exists_internal\u001b[1;34m(checkpoint_prefix)\u001b[0m\n\u001b[0;32m    381\u001b[0m   pathname = _prefix_to_checkpoint_path(checkpoint_prefix,\n\u001b[0;32m    382\u001b[0m                                         saver_pb2.SaverDef.V2)\n\u001b[1;32m--> 383\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_matching_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_matching_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mget_matching_files\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    348\u001b[0m   \u001b[1;33m*\u001b[0m  \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfilesystem\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mlisting\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m   \"\"\"\n\u001b[1;32m--> 350\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mget_matching_files_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Yawer\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[1;34m(pattern)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;31m# Convert the filenames to string from bytes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         for matching_filename in _pywrap_file_io.GetMatchingFiles(\n\u001b[0m\u001b[0;32m    409\u001b[0m             compat.as_bytes(pattern))\n\u001b[0;32m    410\u001b[0m     ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: FindFirstFile failed for: assets/distilled : The system cannot find the path specified.\r\n; No such process"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience=20, verbose=1)\n",
    "\n",
    "'''If you wish to train your own model instead of loading one from checkpoint, remove the checkpoint.'''\n",
    "# os.remove('assets/distilled/checkpoint')\n",
    "# for f in glob.glob('assets/distilled/tree-model*'):\n",
    "#     os.remove(f)\n",
    "\n",
    "tree.maybe_train(\n",
    "    sess=sess, data_train=(x_train_flat, y_train_soft), data_valid=(x_valid_flat, y_valid),\n",
    "    batch_size=batch_size, epochs=epochs, callbacks=[es], distill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.evaluate(x=x_valid_flat, y=y_valid, batch_size=batch_size)\n",
    "tree.evaluate(x=x_test_flat, y=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing learned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(sess, tree, img_rows, img_cols, img_chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to read the visual\n",
    "\n",
    "Exactly as in the [[paper](https://arxiv.org/pdf/1711.09784.pdf)]:\n",
    "* Number **below** any **leaf** denotes `argmax()` of learned distribution, thus final static **prediction** of the (bigot, not expert!) leaf.\n",
    "* Numbers **above** any **inner node** denote the **set of possible predictions** in the sub-tree of the given node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing decision path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = 9\n",
    "\n",
    "# get (reproducibly) pseudo-random example of chosen digit\n",
    "np.random.seed(0)\n",
    "sample_index = np.random.choice(np.where(np.argmax(y_test, axis=1)==digit)[0])\n",
    "input_img = x_test[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(sess, tree, img_rows, img_cols, img_chans, input_img=input_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to read the visual\n",
    "\n",
    "* The <span style=\"color:green\">**maximum probability path**</span> leading **to final prediction** is now denoted by <span style=\"color:green\"> **green arrows**</span>\n",
    "* Number **below** any given **inner node** on this <span style=\"color:green\">**path**</span> denotes the **pre-activation logit** $ = (\\beta (\\mathbf{xw}_i + b_i))$.\n",
    "    * This is basically just a **biased** ($b_i$) and **scaled** ($\\beta$) **correlation** of **input** ($\\mathbf{x}$) with the given **mask** ($\\mathbf{w}_i$).\n",
    "    * From the definition of $\\sigma$ activation function, the choice of branch breaks around `0`.\n",
    "    * From the definition of **branching** in the [[paper](https://arxiv.org/pdf/1711.09784.pdf)], **negative** correlations branch **to the left**, while **positive** correlations branch **to the right**.\n",
    "\n",
    "<img src=\"assets/img/branching.png\" width=\"35%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(sess, tree, img_rows, img_cols, img_chans, input_img=input_img, show_correlation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to read the visual\n",
    "\n",
    "* On the <span style=\"color:green\">**maximum probability path**</span> there are now **correlations** of the **input image** with the **node masks**.\n",
    "* The **homogeneous area** gives a frame of reference for color of `0`s.\n",
    "    * It always corresponds to the **black area in the input image**, but due to lack of normalization (yes, I'm the lazy one here), it ends up as different shade of gray in each subplot.\n",
    "    * All **lighter pixels** from this correspond to **positive correlation coefficients**.\n",
    "    * All **darker pixels** correspond to **negative correlation coefficients**.\n",
    "\n",
    "_Note: In the last input-masked kernel on the path to prediction, notice how model recognizes `9`s from `7`s._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the inference example as animation, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('assets/img/infer'):\n",
    "    os.mkdir('assets/img/infer')\n",
    "\n",
    "draw_tree(sess, tree, img_rows, img_cols, img_chans,\n",
    "          input_img=input_img,\n",
    "          savepath='assets/img/infer/0.png')\n",
    "draw_tree(sess, tree, img_rows, img_cols, img_chans,\n",
    "          input_img=input_img, show_correlation=True,\n",
    "          savepath='assets/img/infer/1.png')\n",
    "\n",
    "!convert -delay 100 -loop 0 assets/img/infer/*.png assets/img/infer.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing the progress of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('assets/img/epoch'):\n",
    "    os.mkdir('assets/img/epoch')\n",
    "\n",
    "if not os.path.isdir('assets/img/sample'):\n",
    "    os.mkdir('assets/img/sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = brand_new_tfsession(sess)\n",
    "\n",
    "tree = SoftBinaryDecisionTree(tree_depth, n_features, n_classes,\n",
    "    penalty_strength=penalty_strength, penalty_decay=penalty_decay,\n",
    "    inv_temp=inv_temp, ema_win_size=ema_win_size, learning_rate=learning_rate)\n",
    "tree.build_model()\n",
    "\n",
    "tree.initialize_variables(sess, x_train_flat, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelImageSaver(Callback):\n",
    "    def __init__(self, display, limit):\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "        self.limit = limit\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        draw_tree(sess, tree, img_rows, img_cols, img_chans,\n",
    "                  savepath='assets/img/epoch/{:04}.png'.format(0))\n",
    "        draw_tree(sess, tree, img_rows, img_cols, img_chans,\n",
    "                  savepath='assets/img/sample/{:07}.png'.format(0))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        draw_tree(sess, tree, img_rows, img_cols, img_chans,\n",
    "                  savepath='assets/img/epoch/{:04}.png'.format(epoch+1))\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0 and self.seen <= self.limit:\n",
    "            draw_tree(sess, tree, img_rows, img_cols, img_chans,\n",
    "                      savepath='assets/img/sample/{:07}.png'.format(self.seen))\n",
    "\n",
    "image_saver = ModelImageSaver(1000, 250000)\n",
    "# save image after each 1000th training example\n",
    "# save max 250 images (corresponds to first 5 training epochs)\n",
    "\n",
    "tree.model.fit(x=x_train_flat, y=y_train_soft, validation_data=(x_valid_flat, y_valid),\n",
    "               batch_size=batch_size, epochs=40, callbacks=[image_saver]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling snapshots into animation\n",
    "**Note**: converting captured series of PNG images into a GIF animation with `makegif.sh` requires `bash` environment with `convert` CLI tool available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Epoch-wise compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./makegif.sh epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![epoch.gif](assets/img/epoch.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample-wise compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./makegif.sh sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sample.gif](assets/img/sample.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elaborating\n",
    "\n",
    "![deeper.jpg](assets/img/deeper.jpg)\n",
    "\n",
    "By now, you should know what's coming..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = brand_new_tfsession(sess)\n",
    "\n",
    "tree = SoftBinaryDecisionTree(tree_depth, n_features, n_classes,\n",
    "    penalty_strength=penalty_strength, penalty_decay=penalty_decay,\n",
    "    inv_temp=inv_temp, ema_win_size=ema_win_size, learning_rate=learning_rate)\n",
    "tree.build_model()\n",
    "\n",
    "tree.initialize_variables(sess, x_train_flat, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.model.fit(x=x_train_flat, y=y_train_soft, validation_data=(x_valid_flat, y_valid),\n",
    "               batch_size=batch_size, epochs=3);\n",
    "\n",
    "# os.mkdir('assets/depth-{}'.format(tree_depth))\n",
    "# tree.save_variables(sess, 'assets/depth-{}/tree-model'.format(tree_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(sess, tree, img_rows, img_cols, img_chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorry, but deeper than this was not so visually appealing and would take much longer to train to a reasonable performance to even motivate examination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final word\n",
    "\n",
    "If you're reading this, I believe you are interested in this implementation, so please don't hesitate to **try it yourself** :)\n",
    "\n",
    "* tune hyperparameters of the tree model\n",
    "    * try out different depths and penalty parameters (strength, decay)\n",
    "    * implement dynamic inverse temperature ($\\beta$), scheduled as a function of training step / epoch\n",
    "* try out different dataset, the approach is generic enough!\n",
    "\n",
    "If you get any interesting results with this implementation, feel free to share them as an [issue](https://github.com/lmartak/distill-nn-tree/issues). Also feel free to improve this repo by submitting a [PR](https://github.com/lmartak/distill-nn-tree/pulls) or just making your own [fork](https://github.com/lmartak/distill-nn-tree/network/members).\n",
    "\n",
    "\n",
    "If you feel adventurous, you could try:\n",
    "* improve `draw_tree`'s correlation mode by normalizing the shade of gray around fixed-`0` color shade\n",
    "* add similar notebook with whole training, distillation & evaluation lifecycle on different dataset (e.g. `cifar-10.ipynb` for [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset)\n",
    "    * This would probably require colorful masks and some experimenting with their normalization for the purposes of visualization, but could be fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1gpu",
   "language": "python",
   "name": "tf1gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
